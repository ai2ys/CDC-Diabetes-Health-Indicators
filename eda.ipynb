{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDC Diabetes Health Indicators\n",
    "\n",
    "**Task:** This midterm project aims to build a service that predicts whether a patient has diabetes, is pre-diabetic, or healthy using \"Diabetes Health Indicators Dataset\" provided by the CDC. \n",
    "\n",
    "\n",
    "üîó Dataset page: [CDC Diabetes Health Indicators](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of dataset information\n",
    "\n",
    "Information provided on the dataset page (see link previous section):\n",
    "\n",
    "**Dataset information**\n",
    "- The \"Diabetes Health Indicators Dataset\" is available on the UCI Machine Learning Repository.\n",
    "- Created to to better understand the relationship between lifestyle and diabetes in the US.\n",
    "- The CDC funded the creation of the dataset. \n",
    "- Cross validation or a fixed train-test split could be used for data splits. \n",
    "- The dataset contains sensitive data such as gender, income, and education level. \n",
    "- The dataset contains **21 feature variables (categorical and integer)** and **1 target variable (binary)**.\n",
    "- Each row represents a person participating in the study. \n",
    "- Data preprocessing was performed by bucketing of age. The dataset has no missing values. \n",
    "\n",
    "\n",
    "**Quoted from the dataset page**<br>\n",
    "\n",
    "> *\"The Diabetes Health Indicators Dataset contains healthcare statistics and lifestyle survey information about people in general along with their diagnosis of diabetes. The 35 features consist of some demographics, lab test results, and answers to survey questions for each patient. The target variable for classification is whether a patient has diabetes, is pre-diabetic, or healthy.\"*\n",
    "\n",
    "**Remark on the quote above**<br>\n",
    "The quote states that the dataset contains 35 features. However, the dataset page further states\n",
    "\n",
    ">|  | Information |\n",
    ">| :--- | :--- |\n",
    ">| Dataset Characteristics | Tabular, Multivariate |\n",
    ">| Subject Area | Life Science |\n",
    ">| Associated Tasks | Classification |\n",
    ">| Feature Type | Categorical, Integer |\n",
    ">| \\# Instances | 253680 |\n",
    ">| \\# Features | 21 |\n",
    "\n",
    "üí°We will check this discrepancy in when digging into the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "**Download of the dataset is provided via**\n",
    "\n",
    "1. Python API using the `ucimlrepo` package.\n",
    "    - Code provided by the dataset page:\n",
    "\n",
    "        ```python\n",
    "        from ucimlrepo import fetch_ucirepo \n",
    "        # fetch dataset \n",
    "        cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "        # data (as pandas dataframes) \n",
    "        X = cdc_diabetes_health_indicators.data.features \n",
    "        y = cdc_diabetes_health_indicators.data.targets \n",
    "        # metadata \n",
    "        print(cdc_diabetes_health_indicators.metadata) \n",
    "        # variable information \n",
    "        print(cdc_diabetes_health_indicators.variables) \n",
    "        ```\n",
    "    - The metadata of the downloaded dataset, using the code above, includes a download link for the dataset in CSV format. However, no additional information is provided along with the CSV file:<br>\n",
    "    https://archive.ics.uci.edu/static/public/891/data.csv\n",
    "    \n",
    "1. On the project page [CDC Diabetes Health Indicators](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators) there is a reference to the dataset source which redirects to a [Kaggle dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Data download used in this project**\n",
    "\n",
    "- ‚úÖ In this project the `ucimlrepo` will be used to download the dataset and all relevant metadata. \n",
    "\n",
    "- üíæ The dataset's dataframe as well as all other relevant data will be stored in the [./data_cdc_diabetes_health_indicators](data_cdc_diabetes_health_indicators) folder locally. \n",
    "\n",
    "- üí° Downloading and then reusing the downloaded data instead of redownloading it using the `ucimlrepo` package done to ensure reproducibility of the project in case the dataset is not available anymore or changes over time.\n",
    "\n",
    "\n",
    "**Further information on the dataset**\n",
    "\n",
    "‚ÑπÔ∏è More information about the features will be revealed after downloading the dataset and revealing the dataset's metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.utils.capture import capture_output\n",
    "from IPython.display import display\n",
    "\n",
    "from lib.eda_functions import plot_boxplots, plot_histograms, plot_histograms, plot_boxplots_normalize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '/workspace/data_cdc_diabetes_health_indicators'\n",
    "# data set id of the cdc diabetes health indicators\n",
    "dataset_id = 891\n",
    "file_name = f'data_{dataset_id}.csv'\n",
    "path_data_csv = os.path.join(path_dir, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° The variables below have only been set to `True` for the first run to download all relevent data in the subsequent cell. Afterwards they can be set to `False` to avoid downloading the data again. For reproducing the here presented results please use the default values using the already downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has already been downloaded and saved as json and csv.\n",
    "# Therefore both variable can be set to False.\n",
    "# Value True was only used for initial download.\n",
    "\n",
    "# modify only in case of downloading again\n",
    "download = False\n",
    "# only used for writing additional information to local files \n",
    "write_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download:\n",
    "    cdc_diabetes_health_indicators = fetch_ucirepo(id=dataset_id)\n",
    "    \n",
    "    # create dataframe from data and targets\n",
    "    X = cdc_diabetes_health_indicators.data.features\n",
    "    y = cdc_diabetes_health_indicators.data.targets\n",
    "    ids = cdc_diabetes_health_indicators.data.ids\n",
    "    df = pd.concat([ids, y, X], axis=1)\n",
    "    df.set_index('ID', inplace=True)\n",
    "    df = pd.concat([ids, y, X], axis=1)\n",
    "\n",
    "    # read variables\n",
    "    variables = cdc_diabetes_health_indicators.variables\n",
    "\n",
    "    print(\"keys:\\n\", cdc_diabetes_health_indicators.keys())\n",
    "    print(\"metadata keys:\\n\", cdc_diabetes_health_indicators.metadata)\n",
    "    display(cdc_diabetes_health_indicators.variables)\n",
    "    if write_files:\n",
    "        df.to_csv(path_data_csv, index=False)\n",
    "        cdc_diabetes_health_indicators.variables.to_csv(\n",
    "            os.path.join(path_dir, 'variables.csv'), index=False)\n",
    "        # write the following to a json file\n",
    "        json_data = {}\n",
    "        json_data['keys'] = list(cdc_diabetes_health_indicators.keys())\n",
    "        json_data['metadata_keys'] = list(cdc_diabetes_health_indicators.metadata.keys())\n",
    "        json_data['data'] = {'headers': cdc_diabetes_health_indicators.data.headers.tolist(),}\n",
    "        json_data['variables'] = 'see ./variables.csv for more information' \n",
    "        json_data['metadata'] = dict(cdc_diabetes_health_indicators.metadata)\n",
    "\n",
    "        with open(os.path.join(path_dir, 'cdc_diabetes_health_indicators.json'), 'w') as f:\n",
    "            f.write(json.dumps(json_data, indent=2))\n",
    "else:\n",
    "    df = pd.read_csv(path_data_csv, index_col='ID')\n",
    "    variables = pd.read_csv(os.path.join(path_dir, 'variables.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Diabetes_binary  HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  \\\n",
       "ID                                                                      \n",
       "0                 0       1         1          1   40       1       0   \n",
       "1                 0       0         0          0   25       1       0   \n",
       "2                 0       1         1          1   28       0       0   \n",
       "3                 0       1         0          1   27       0       0   \n",
       "4                 0       1         1          1   24       0       0   \n",
       "\n",
       "    HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "ID                                              ...                  \n",
       "0                      0             0       0  ...              1   \n",
       "1                      0             1       0  ...              0   \n",
       "2                      0             0       1  ...              1   \n",
       "3                      0             1       1  ...              1   \n",
       "4                      0             1       1  ...              1   \n",
       "\n",
       "    NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  \\\n",
       "ID                                                                            \n",
       "0             0        5        18        15         1    0    9          4   \n",
       "1             1        3         0         0         0    0    7          6   \n",
       "2             1        5        30        30         1    0    9          4   \n",
       "3             0        2         0         0         0    0   11          3   \n",
       "4             0        2         3         0         0    0   11          5   \n",
       "\n",
       "    Income  \n",
       "ID          \n",
       "0        3  \n",
       "1        1  \n",
       "2        8  \n",
       "3        6  \n",
       "4        4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Information about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about dataset columns\n",
    "\n",
    "From the information it can be seen that the target column is `Diabetes_binary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables (Target and Features)\n",
    "\n",
    "| ID | Type | Description | \n",
    "| --- | --- | --- |\n",
    "| ID | Integer | Patient ID |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Target | Type | Description | \n",
    "| --- | --- | --- |\n",
    "| Diabetes_binary | Binary | 0 = no diabetes<br>1 = prediabetes or diabetes |\n",
    "\n",
    "Features in are sorted in the table below using their data type:\n",
    "- Integer\n",
    "- Categrical\n",
    "- Binary\n",
    "\n",
    "> Information for binary features (except for feature `Sex`):\n",
    "> - `0` = `no` \n",
    "> - `1` = `yes`\n",
    "\n",
    "| Features | Type | Description | \n",
    "| --- | --- | --- |\n",
    "| BMI | Integer | Body Mass Index |\n",
    "| MentHlth | Integer | Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good? scale 1-30 days |\n",
    "| PhysHlth | Integer | Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good? scale 1-30 days |\n",
    "|  |  |  |\n",
    "| GenHlth | Integer (Categorical) | Would you say that in general your health is: scale 1-5<br>1 = excellent<br>2 = very good<br> 3 = good<br> 4 = fair<br> 5 = poor |\n",
    "| Age | Integer (Categorical) | Age,13-level age category (_AGEG5YR see codebook)<br>1 = 18-24<br>9 = 60-64<br> 13 = 80 or older |\n",
    "| Education | Integer (Categorical) | Education level (EDUCA see codebook) scale 1-6<br>1 = Never attended school or only kindergarten<br>2 = Grades 1 through 8 (Elementary)<br>3 = Grades 9 through 11 (Some high school)<br>4 = Grade 12 or GED (High school graduate)<br>5 = College 1 year to 3 years (Some college or technical school)<br>6 = College 4 years or more (College graduate) |\n",
    "| Income | Integer (Categorical) | Income scale (INCOME2 see codebook) scale 1-8<br> 1 = less than $10,000<br> 5 = less than $35,000<br> 8 = $75,000 or more\" |\n",
    "|  |  |  |\n",
    "| Sex | Binary | Sex, 0 = female 1 = male |\n",
    "| HighBP | Binary | High blood preasure |\n",
    "| HighChol | Binary | High cholesterol |\n",
    "| CholCheck | Binary | Cholesterol check in 5 years |\n",
    "| Smoker | Binary | Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] |\n",
    "| Stroke | Binary | (Ever told) you had a stroke. |\n",
    "| HeartDiseaseorAttack | Binary | Coronary heart disease (CHD) or myocardial infarction (MI) |\n",
    "| PhysActivity | Binary | Physical activity in past 30 days - not including job< |\n",
    "| Fruits | Binary | Consume Fruit 1 or more times per day |\n",
    "| Veggies | Binary | Consume Vegetables 1 or more times per day |\n",
    "| HvyAlcoholConsump | Binary | Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week)|\n",
    "| AnyHealthcare | Binary | \"Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. |\n",
    "| NoDocbcCost | Binary | Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? |\n",
    "| ffWalk | Binary | Do you have serious difficulty walking or climbing stairs? |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype\n",
      "---  ------                --------------   -----\n",
      " 0   Diabetes_binary       253680 non-null  int64\n",
      " 1   HighBP                253680 non-null  int64\n",
      " 2   HighChol              253680 non-null  int64\n",
      " 3   CholCheck             253680 non-null  int64\n",
      " 4   BMI                   253680 non-null  int64\n",
      " 5   Smoker                253680 non-null  int64\n",
      " 6   Stroke                253680 non-null  int64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  int64\n",
      " 8   PhysActivity          253680 non-null  int64\n",
      " 9   Fruits                253680 non-null  int64\n",
      " 10  Veggies               253680 non-null  int64\n",
      " 11  HvyAlcoholConsump     253680 non-null  int64\n",
      " 12  AnyHealthcare         253680 non-null  int64\n",
      " 13  NoDocbcCost           253680 non-null  int64\n",
      " 14  GenHlth               253680 non-null  int64\n",
      " 15  MentHlth              253680 non-null  int64\n",
      " 16  PhysHlth              253680 non-null  int64\n",
      " 17  DiffWalk              253680 non-null  int64\n",
      " 18  Sex                   253680 non-null  int64\n",
      " 19  Age                   253680 non-null  int64\n",
      " 20  Education             253680 non-null  int64\n",
      " 21  Income                253680 non-null  int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 44.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datatypes for all columns is `int64`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating varariables for the target name and columns containing different data types:\n",
    "- feature_names_binary\n",
    "- feature_names_categorical\n",
    "- feature_names_integer\n",
    "\n",
    "üí° Data type can stay `int64` for all columns. Going to apply OneHotEncoding to all categorical columns later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'Diabetes_binary'\n",
    "feature_names_binary = [\n",
    "    'Sex', \n",
    "    'HighBP', \n",
    "    'HighChol', \n",
    "    'CholCheck', \n",
    "    'Smoker', \n",
    "    'Stroke', \n",
    "    'HeartDiseaseorAttack',\n",
    "    'PhysActivity',\n",
    "    'Fruits',\n",
    "    'Veggies',\n",
    "    'HvyAlcoholConsump',\n",
    "    'AnyHealthcare',\n",
    "    'NoDocbcCost',\n",
    "    'DiffWalk',\n",
    "]\n",
    "feature_names_integer = ['BMI']\n",
    "feature_names_categorical = ['GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "\n",
    "feature_names = feature_names_binary + feature_names_integer + feature_names_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using assertions to check if the data columns have been split correctly into `Binary`, `Categorical` and `Integer`.\n",
    "\n",
    "- Checking that the sum of values in the `feature_<type>` lists is equal to the number of columns in the data frame\n",
    "- Checking that the `feature_<type>` lists do not overlap\n",
    "- Checking that the `feature_<type>` lists contain all columns of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create assert in case column numbers do not match\n",
    "len_all_features = len(feature_names_binary) + len(feature_names_integer) + len(feature_names_categorical)\n",
    "assert df.columns.size == len_all_features + 1, \\\n",
    "    f'Number of columns in dataframe ({df.columns.size}) does not match the number of features ({len_all_features + 1})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create asssert in case names overlap\n",
    "set_binary_intersect_integer = set(feature_names_binary).intersection(set(feature_names_integer))\n",
    "set_binary_intersect_categorical = set(feature_names_binary).intersection(set(feature_names_categorical))\n",
    "set_integer_intersect_categorical = set(feature_names_integer).intersection(set(feature_names_categorical))\n",
    "\n",
    "\n",
    "assert target_name not in set_binary_intersect_integer, \\\n",
    "    f'Features overlap between binary and integer features: {set_binary_intersect_integer}'\n",
    "assert target_name not in set_binary_intersect_categorical, \\\n",
    "    f'Features overlap between binary and categorical features: {set_binary_intersect_categorical}'\n",
    "assert target_name not in set_integer_intersect_categorical, \\\n",
    "    f'Features overlap between integer and categorical features: {set_integer_intersect_categorical}'\n",
    "\n",
    "assert set_binary_intersect_integer == set(), \\\n",
    "    f'Features overlap between binary and integer features: {set_binary_intersect_integer}'\n",
    "assert set_binary_intersect_categorical == set(), \\\n",
    "    f'Features overlap between binary and categorical features: {set_binary_intersect_categorical}'\n",
    "assert set_integer_intersect_categorical == set(), \\\n",
    "    f'Features overlap between integer and categorical features: {set_integer_intersect_categorical}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create assert in case target column is not in dataframe\n",
    "set_diff = set(df.columns).difference(set([target_name]+feature_names))\n",
    "assert set_diff == set(), \\\n",
    "    f'Dataframe contains columns not covered by the other variables: {set_diff}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Set Information\n",
    "\n",
    "Checking dataset for\n",
    "- unique values\n",
    "- missing values\n",
    "- duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is said that the dataset has no missing values, but checking to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_issnull = df.isnull().any()\n",
    "sum_of_issnull_cols = df.loc[:,indices_issnull].isnull().sum()\n",
    "frac_of_isnull_cols = sum_of_issnull_cols/len(df)\n",
    "print(f\"Missing data - absolute values: \")\n",
    "print(\"---\")\n",
    "print(sum_of_issnull_cols)\n",
    "print(\"\\n===\\n\")\n",
    "print(\"Missing data - percent\")\n",
    "print(\"---\")\n",
    "print(frac_of_isnull_cols.round(decimals=3)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ There is no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patient ID, is used as dataframe index. We are now checkin if there are duplicate rows (not including the ID) and explain how we are going to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows:  253680\n",
      "Number of duplicates:   24206\n",
      "Percentage of duplicates: 9.54%\n"
     ]
    }
   ],
   "source": [
    "indices_duplicates = df_original.duplicated(keep='first')\n",
    "num_total = len(df_original)\n",
    "num_duplicates = indices_duplicates.sum()\n",
    "print(f\"Total number of rows: {num_total:7d}\")\n",
    "print(f\"Number of duplicates: {num_duplicates:7d}\")\n",
    "print(f\"Percentage of duplicates: {num_duplicates/num_total:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oberservation:**  \n",
    "There are almost 10% of duplicate rows in the dataset.\n",
    "\n",
    "**Explanation:**\n",
    "üí° Except for the `BMI` feature, which is only stored as `Integer`, the dataset consists of only `Binary` and `Categorical` features. This means that the duplicate rows are not duplicate patients, but different patients displaying the same values for all features due to the nature of the data types.\n",
    "\n",
    "**Handling:**\n",
    "We are now going to check, if the patient IDs are unique, comparing the index length with the number of unique patient IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Index length equal df_original.index.size == df_original.index.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "print(f\"Number of rows after dropping duplicates: {len(df):7d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Splitting into Train and Test\n",
    "- ‚ÑπÔ∏è If there is no separate test datasset available, it is important to split the data into `test` and `train` (including `val`). Before analyzing the data any further.\n",
    "    - 60% `train`\n",
    "    - 20% `val`\n",
    "    - 20% `test`\n",
    "\n",
    "- üí°Using a seed point (`random_state`) to make sure the split is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "frac_train = 0.6\n",
    "frac_val = 0.2\n",
    "frac_test = 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=frac_test, random_state=seed, shuffle=True)\n",
    "df_train, df_val = train_test_split(df_train, test_size=frac_val/frac_train, random_state=seed, shuffle=True)\n",
    "\n",
    "overall_len = len(df_train) + len(df_val) + len(df_test)    \n",
    "overall_len == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_issnull = df_train.isnull().any()\n",
    "sum_of_issnull_cols = df_train.loc[:,indices_issnull].isnull().sum()\n",
    "frac_of_isnull_cols = sum_of_issnull_cols/len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploratory Data Analysis (EDA) of the train split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we must never investigate our `test` split, we are going to do the EDA on the `train` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_train.hist(figsize=(10, 7), bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Regarding the target column `Diabetes_binary` it can be seen that the data is imbalanced. There are more healthy people than people with diabetes. This is important to keep in mind when evaluating the model.\n",
    "\n",
    "Furthermore it can be seen that binary columns tend to have the vast amount of entries for one value. Furhtermore are the other variabels  not nomally distributed. This is important to keep in mind when choosing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix, abbreviate the column names for better readability\n",
    "corr_matrix = df_train.corr()\n",
    "# set upper triangle to nan incluing the diagonal\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "corr_matrix = corr_matrix.mask(mask)\n",
    "corr_matrix_short_names = corr_matrix.rename(columns=lambda x: f'{x[:5]}...' if len(x) > 8 else x)\n",
    "display(corr_matrix_short_names.style.background_gradient(cmap='seismic', axis=None, vmin=-1, vmax=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(corr_matrix, annot=True, ax=ax, cmap='seismic', fmt='.2f', vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display features with highest pairwise correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all pairs of columns by their abslute correlation value, add the absolute correlation value\n",
    "corr_matrix_abs = corr_matrix.abs()\n",
    "\n",
    "corr_matrix_abs = corr_matrix_abs.unstack()\n",
    "corr_matrix_abs = corr_matrix_abs.sort_values(ascending=False)\n",
    "# corr_matrix_abs = corr_matrix_abs[corr_matrix_abs != 1]\n",
    "corr_matrix_abs = corr_matrix_abs.reset_index()\n",
    "corr_matrix_abs.columns = ['feature_1', 'feature_2', 'abs_corr']\n",
    "corr_matrix_abs.dropna(how='any', axis=0, inplace=True)\n",
    "corr_matrix_abs.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import boxcox\n",
    "# normalized_data = boxcox(df.Solids)\n",
    "# sns.distplot(normalized_data[0], label='boxcox')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solids_norm = (df.Solids-df.Solids.mean())/df.Solids.std()\n",
    "# sns.distplot(df.Solids, label='orig')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_val, y_pred):\n",
    "    # overall accuracy\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # calculate accuracy for each of the both classes separately\n",
    "    accuracy_class_0 = accuracy_score(y_val[y_val==0], y_pred[y_val==0])\n",
    "    accuracy_class_1 = accuracy_score(y_val[y_val==1], y_pred[y_val==1])\n",
    "    print(\"Accuracy class 0:\", accuracy_class_0)\n",
    "    print(\"Accuracy class 1:\", accuracy_class_1)\n",
    "    # print the classification report\n",
    "    print(\"Classification report:\\n\", classification_report(y_val, y_pred))\n",
    "    # print the confusion matrix\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "    print(\"Confusion matrix normalized:\\n\", confusion_matrix(y_val, y_pred, normalize='true'))\n",
    "\n",
    "def plot_confusion_matrix(y_val, y_pred):\n",
    "    # plot confusion matrix and normalized confusion matrix side by side\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    cm_norm = confusion_matrix(y_val, y_pred, normalize='true')\n",
    "    ax[0].set_title('Confusion Matrix')\n",
    "    ax[1].set_title('Normalized Confusion Matrix')\n",
    "    ConfusionMatrixDisplay(cm).plot(ax=ax[0])\n",
    "    ConfusionMatrixDisplay(cm_norm).plot(ax=ax[1])\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_and_precision_recall_curve(y_val, y_pred_proba):\n",
    "    # plot roc curve and precision recall curve side by side\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot(ax=ax[0])\n",
    "    ax[0].plot([0, 1], [0, 1], 'k--')\n",
    "    ax[0].set_title('ROC Curve')\n",
    "    ax[0].legend(loc=\"lower right\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "    average_precision = average_precision_score(y_val, y_pred_proba)\n",
    "    PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=average_precision).plot(ax=ax[1])\n",
    "    ax[1].set_title('Precision Recall Curve')\n",
    "    ax[1].legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(model, X_train, y_train):\n",
    "    # plot the feature importance\n",
    "    result = permutation_importance(model, X_train, y_train, n_repeats=10, random_state=seed)\n",
    "    sorted_idx = result.importances_mean.argsort()\n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    ax.boxplot(result.importances[sorted_idx].T, vert=False, labels=X_train.columns[sorted_idx])\n",
    "    ax.set_title(\"Permutation Importances (train set)\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a logistic regression model\n",
    "\n",
    "# define the target column\n",
    "target_column = 'Diabetes_binary'\n",
    "# define the feature columns\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# split the data into train and val data\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train[target_column]\n",
    "X_val = df_val[feature_columns]\n",
    "y_val = df_val[target_column]\n",
    "\n",
    "class_weight = len(y_train) / np.bincount(y_train)\n",
    "class_weight = {0: class_weight[0], 1: class_weight[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = LogisticRegression(random_state=seed, max_iter=1000)\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "# predict the target values\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_proba = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "print_metrics(y_val, y_pred)\n",
    "plot_confusion_matrix(y_val, y_pred)\n",
    "plot_roc_and_precision_recall_curve(y_val, y_pred_proba)\n",
    "plot_feature_importance(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = LogisticRegression(random_state=seed, max_iter=1000, class_weight='balanced')\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "# predict the target values\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_proba = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "print_metrics(y_val, y_pred)\n",
    "plot_confusion_matrix(y_val, y_pred)\n",
    "plot_roc_and_precision_recall_curve(y_val, y_pred_proba)\n",
    "plot_feature_importance(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the model\n",
    "model = LogisticRegression(random_state=seed, max_iter=1000, class_weight=class_weight)\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "# predict the target values\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_proba = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "print_metrics(y_val, y_pred)\n",
    "plot_confusion_matrix(y_val, y_pred)\n",
    "plot_roc_and_precision_recall_curve(y_val, y_pred_proba)\n",
    "plot_feature_importance(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve and precision recall curve side by side    \n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "#determine sample weights for roc curve\n",
    "sample_weight = np.ones(len(y_val))\n",
    "sample_weight[0] = 1/sum(y_val==0)\n",
    "sample_weight[1] = 1/sum(y_val==1)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba, sample_weight=sample_weight)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot(ax=ax[0])\n",
    "ax[0].plot([0, 1], [0, 1], 'k--')\n",
    "ax[0].set_title('ROC Curve')\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba, sample_weight=sample_weight)\n",
    "average_precision = average_precision_score(y_val, y_pred_proba)\n",
    "PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=average_precision).plot(ax=ax[1])\n",
    "ax[1].set_title('Precision Recall Curve')\n",
    "ax[1].legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
